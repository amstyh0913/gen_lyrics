{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lyrics_df = pd.read_csv('lyrics.csv')\n",
    "lyrics_df = lyrics_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "266556\n",
      "Index(['index', 'song', 'year', 'artist', 'genre', 'lyrics'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index             song  year           artist genre  \\\n",
       "0      0        ego-remix  2009  beyonce-knowles   Pop   \n",
       "1      1     then-tell-me  2009  beyonce-knowles   Pop   \n",
       "2      2          honesty  2009  beyonce-knowles   Pop   \n",
       "3      3  you-are-my-rock  2009  beyonce-knowles   Pop   \n",
       "4      4    black-culture  2009  beyonce-knowles   Pop   \n",
       "\n",
       "                                              lyrics  \n",
       "0  Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1  playin' everything so easy,\\nit's like you see...  \n",
       "2  If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3  Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4  Party the people, the people the party it's po...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(lyrics_df))\n",
    "print(lyrics_df.columns)\n",
    "lyrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1988, 67, 1968, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 702, 1986, 1987, 1985, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 112}\n",
      "{'Jazz', 'Hip-Hop', 'Folk', 'Metal', 'Not Available', 'Rock', 'Country', 'R&B', 'Indie', 'Electronic', 'Pop', 'Other'}\n"
     ]
    }
   ],
   "source": [
    "print(set(lyrics_df['year']))\n",
    "print(set(lyrics_df['genre']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh baby, how you doing?\n",
      "You know I'm gonna cut right to the chase\n",
      "Some women were made but me, myself\n",
      "I like to think that I was created for a special purpose\n",
      "You know, what's more special than you? You feel me\n",
      "It's on baby, let's get lost\n",
      "You don't need to call into work 'cause you're the boss\n",
      "For real, want you to show me how you feel\n",
      "I consider myself lucky, that's a big deal\n",
      "Why? Well, you got the key to my heart\n",
      "But you ain't gonna need it, I'd rather you open up my body\n",
      "And show me secrets, you didn't know was inside\n",
      "No need for me to lie\n",
      "It's too big, it's too wide\n",
      "It's too strong, it won't fit\n",
      "It's too much, it's too tough\n",
      "He talk like this 'cause he can back it up\n",
      "He got a big ego, such a huge ego\n",
      "I love his big ego, it's too much\n",
      "He walk like this 'cause he can back it up\n",
      "Usually I'm humble, right now I don't choose\n",
      "You can leave with me or you could have the blues\n",
      "Some call it arrogant, I call it confident\n",
      "You decide when you find on what I'm working with\n",
      "Damn I know I'm killing you with them legs\n",
      "Better yet them thighs\n",
      "Matter a fact it's my smile or maybe my eyes\n",
      "Boy you a site to see, kind of something like me\n",
      "It's too big, it's too wide\n",
      "It's too strong, it won't fit\n",
      "It's too much, it's too tough\n",
      "I talk like this 'cause I can back it up\n",
      "I got a big ego, such a huge ego\n",
      "But he love my big ego, it's too much\n",
      "I walk like this 'cause I can back it up\n",
      "I, I walk like this 'cause I can back it up\n",
      "I, I talk like this 'cause I can back it up\n",
      "I, I can back it up, I can back it up\n",
      "I walk like this 'cause I can back it up\n",
      "It's too big, it's too wide\n",
      "It's too strong, it won't fit\n",
      "It's too much, it's too tough\n",
      "He talk like this 'cause he can back it up\n",
      "He got a big ego, such a huge ego, such a huge ego\n",
      "I love his big ego, it's too much\n",
      "He walk like this 'cause he can back it up\n",
      "Ego so big, you must admit\n",
      "I got every reason to feel like I'm that bitch\n",
      "Ego so strong, if you ain't know\n",
      "I don't need no beat, I can sing it with piano\n"
     ]
    }
   ],
   "source": [
    "lyrics = lyrics_df['lyrics']\n",
    "print(lyrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/yuki/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yuki/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to /home/yuki/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = ['NN', 'VB', 'PRP','JJ']\n",
    "keywords = []\n",
    "train_data = []\n",
    "for lyric in lyrics:\n",
    "    # divide lyric into sentence\n",
    "    if type(lyric) != str:\n",
    "        print(lyric)\n",
    "    sentences = lyric.split('\\n')\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        tags = nltk.pos_tag(words)\n",
    "        # extract keywords\n",
    "        for tag in tags:\n",
    "            if any([ True for p in pos if p in tag[1] ]):\n",
    "                keywords.append(tag[0])\n",
    "        # make train data of keyword and sentence pairs\n",
    "        if len(keywords) > 0:\n",
    "            train_data.append((keywords,sentence))\n",
    "        keywords = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "f = open('train_data.json','w')\n",
    "json.dump(train_data, f, indent = 2, ensure_ascii = False)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
